#!/usr/bin/env python3
"""
LightGBM Binary Classifier v2 ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚ŒãŸã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨Model Monitorã®å‹•ä½œã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚
"""

import boto3
import json
import numpy as np
import pandas as pd
import time
from datetime import datetime
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LightGBMV2Tester:
    """
    LightGBM v2ã®ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self, endpoint_name, region='us-east-1'):
        """
        åˆæœŸåŒ–
        
        Args:
            endpoint_name (str): ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå
            region (str): AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³
        """
        self.endpoint_name = endpoint_name
        self.region = region
        self.runtime = boto3.client('sagemaker-runtime', region_name=region)
        self.s3_client = boto3.client('s3', region_name=region)
        self.sm_client = boto3.client('sagemaker', region_name=region)
        
        logger.info(f"Tester initialized for endpoint: {endpoint_name}")
    
    def generate_test_data(self, n_samples=100, n_features=25):
        """
        ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        
        Args:
            n_samples (int): ã‚µãƒ³ãƒ—ãƒ«æ•°
            n_features (int): ç‰¹å¾´é‡æ•°
            
        Returns:
            np.ndarray: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        """
        logger.info(f"Generating {n_samples} test samples with {n_features} features")
        
        # ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        np.random.seed(42)
        test_data = np.random.randn(n_samples, n_features)
        
        return test_data
    
    def test_single_prediction(self, test_sample=None):
        """
        å˜ä¸€äºˆæ¸¬ã‚’ãƒ†ã‚¹ãƒˆ
        
        Args:
            test_sample (list): ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«ï¼ˆNoneã®å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
            
        Returns:
            dict: äºˆæ¸¬çµæœ
        """
        if test_sample is None:
            test_sample = self.generate_test_data(1, 25)[0].tolist()
        
        logger.info("Testing single prediction...")
        
        try:
            # äºˆæ¸¬å®Ÿè¡Œ
            payload = json.dumps({"instances": [test_sample]})
            
            response = self.runtime.invoke_endpoint(
                EndpointName=self.endpoint_name,
                ContentType='application/json',
                Body=payload
            )
            
            result = json.loads(response['Body'].read().decode())
            
            logger.info("âœ… Single prediction successful")
            logger.info(f"Result: {result}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ Single prediction failed: {str(e)}")
            raise
    
    def test_batch_prediction(self, batch_size=10):
        """
        ãƒãƒƒãƒäºˆæ¸¬ã‚’ãƒ†ã‚¹ãƒˆ
        
        Args:
            batch_size (int): ãƒãƒƒãƒã‚µã‚¤ã‚º
            
        Returns:
            dict: äºˆæ¸¬çµæœ
        """
        logger.info(f"Testing batch prediction with {batch_size} samples...")
        
        try:
            # ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            test_batch = self.generate_test_data(batch_size, 25).tolist()
            
            # äºˆæ¸¬å®Ÿè¡Œ
            payload = json.dumps({"instances": test_batch})
            
            response = self.runtime.invoke_endpoint(
                EndpointName=self.endpoint_name,
                ContentType='application/json',
                Body=payload
            )
            
            result = json.loads(response['Body'].read().decode())
            
            logger.info("âœ… Batch prediction successful")
            logger.info(f"Predicted {len(result['predictions'])} samples")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ Batch prediction failed: {str(e)}")
            raise
    
    def stress_test(self, n_requests=50, interval=1):
        """
        ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆï¼ˆé€£ç¶šãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼‰
        
        Args:
            n_requests (int): ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°
            interval (float): ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”ï¼ˆç§’ï¼‰
            
        Returns:
            dict: ãƒ†ã‚¹ãƒˆçµæœçµ±è¨ˆ
        """
        logger.info(f"Starting stress test: {n_requests} requests with {interval}s interval")
        
        results = {
            'total_requests': n_requests,
            'successful_requests': 0,
            'failed_requests': 0,
            'response_times': [],
            'errors': []
        }
        
        for i in range(n_requests):
            try:
                start_time = time.time()
                
                # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
                test_sample = self.generate_test_data(1, 25)[0].tolist()
                payload = json.dumps({"instances": [test_sample]})
                
                # äºˆæ¸¬å®Ÿè¡Œ
                response = self.runtime.invoke_endpoint(
                    EndpointName=self.endpoint_name,
                    ContentType='application/json',
                    Body=payload
                )
                
                end_time = time.time()
                response_time = end_time - start_time
                
                results['successful_requests'] += 1
                results['response_times'].append(response_time)
                
                if (i + 1) % 10 == 0:
                    logger.info(f"Completed {i + 1}/{n_requests} requests")
                
                time.sleep(interval)
                
            except Exception as e:
                results['failed_requests'] += 1
                results['errors'].append(str(e))
                logger.warning(f"Request {i + 1} failed: {str(e)}")
        
        # çµ±è¨ˆè¨ˆç®—\n        if results['response_times']:\n            results['avg_response_time'] = np.mean(results['response_times'])\n            results['min_response_time'] = np.min(results['response_times'])\n            results['max_response_time'] = np.max(results['response_times'])\n            results['p95_response_time'] = np.percentile(results['response_times'], 95)\n        \n        logger.info(\"âœ… Stress test completed\")\n        logger.info(f\"Success rate: {results['successful_requests']}/{results['total_requests']}\")\n        if results['response_times']:\n            logger.info(f\"Avg response time: {results['avg_response_time']:.3f}s\")\n        \n        return results\n    \n    def check_endpoint_status(self):\n        \"\"\"\n        ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®çŠ¶æ…‹ã‚’ç¢ºèª\n        \n        Returns:\n            dict: ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆæƒ…å ±\n        \"\"\"\n        logger.info(\"Checking endpoint status...\")\n        \n        try:\n            response = self.sm_client.describe_endpoint(\n                EndpointName=self.endpoint_name\n            )\n            \n            status = response['EndpointStatus']\n            logger.info(f\"Endpoint status: {status}\")\n            \n            if status == 'InService':\n                logger.info(\"âœ… Endpoint is ready for inference\")\n            else:\n                logger.warning(f\"âš ï¸  Endpoint is not ready: {status}\")\n            \n            return response\n            \n        except Exception as e:\n            logger.error(f\"âŒ Failed to check endpoint status: {str(e)}\")\n            raise\n    \n    def check_data_capture(self, bucket, s3_prefix):\n        \"\"\"\n        Data Captureãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª\n        \n        Args:\n            bucket (str): S3ãƒã‚±ãƒƒãƒˆå\n            s3_prefix (str): S3ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹\n            \n        Returns:\n            list: Data Captureãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§\n        \"\"\"\n        logger.info(\"Checking data capture files...\")\n        \n        try:\n            response = self.s3_client.list_objects_v2(\n                Bucket=bucket,\n                Prefix=f'{s3_prefix}/datacapture'\n            )\n            \n            files = []\n            if 'Contents' in response:\n                files = response['Contents']\n                logger.info(f\"Found {len(files)} data capture files\")\n                \n                # æœ€æ–°ã®5ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º\n                sorted_files = sorted(files, key=lambda x: x['LastModified'], reverse=True)\n                for file in sorted_files[:5]:\n                    logger.info(f\"  - {file['Key']} ({file['Size']} bytes, {file['LastModified']})\")\n            else:\n                logger.info(\"No data capture files found\")\n            \n            return files\n            \n        except Exception as e:\n            logger.error(f\"âŒ Failed to check data capture: {str(e)}\")\n            return []\n    \n    def run_comprehensive_test(self, bucket=None, s3_prefix=None):\n        \"\"\"\n        åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ\n        \n        Args:\n            bucket (str): S3ãƒã‚±ãƒƒãƒˆåï¼ˆData Captureç¢ºèªç”¨ï¼‰\n            s3_prefix (str): S3ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ï¼ˆData Captureç¢ºèªç”¨ï¼‰\n            \n        Returns:\n            dict: ãƒ†ã‚¹ãƒˆçµæœ\n        \"\"\"\n        logger.info(\"Starting comprehensive test...\")\n        \n        test_results = {\n            'timestamp': datetime.now().isoformat(),\n            'endpoint_name': self.endpoint_name,\n            'tests': {}\n        }\n        \n        try:\n            # 1. ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆçŠ¶æ…‹ç¢ºèª\n            logger.info(\"\\n1. Checking endpoint status...\")\n            endpoint_status = self.check_endpoint_status()\n            test_results['tests']['endpoint_status'] = {\n                'status': endpoint_status['EndpointStatus'],\n                'success': endpoint_status['EndpointStatus'] == 'InService'\n            }\n            \n            # 2. å˜ä¸€äºˆæ¸¬ãƒ†ã‚¹ãƒˆ\n            logger.info(\"\\n2. Testing single prediction...\")\n            try:\n                single_result = self.test_single_prediction()\n                test_results['tests']['single_prediction'] = {\n                    'success': True,\n                    'result': single_result\n                }\n            except Exception as e:\n                test_results['tests']['single_prediction'] = {\n                    'success': False,\n                    'error': str(e)\n                }\n            \n            # 3. ãƒãƒƒãƒäºˆæ¸¬ãƒ†ã‚¹ãƒˆ\n            logger.info(\"\\n3. Testing batch prediction...\")\n            try:\n                batch_result = self.test_batch_prediction()\n                test_results['tests']['batch_prediction'] = {\n                    'success': True,\n                    'batch_size': len(batch_result['predictions'])\n                }\n            except Exception as e:\n                test_results['tests']['batch_prediction'] = {\n                    'success': False,\n                    'error': str(e)\n                }\n            \n            # 4. ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ\n            logger.info(\"\\n4. Running stress test...\")\n            try:\n                stress_result = self.stress_test(n_requests=20, interval=0.5)\n                test_results['tests']['stress_test'] = {\n                    'success': True,\n                    'success_rate': stress_result['successful_requests'] / stress_result['total_requests'],\n                    'avg_response_time': stress_result.get('avg_response_time', 0)\n                }\n            except Exception as e:\n                test_results['tests']['stress_test'] = {\n                    'success': False,\n                    'error': str(e)\n                }\n            \n            # 5. Data Captureç¢ºèª\n            if bucket and s3_prefix:\n                logger.info(\"\\n5. Checking data capture...\")\n                try:\n                    capture_files = self.check_data_capture(bucket, s3_prefix)\n                    test_results['tests']['data_capture'] = {\n                        'success': True,\n                        'file_count': len(capture_files)\n                    }\n                except Exception as e:\n                    test_results['tests']['data_capture'] = {\n                        'success': False,\n                        'error': str(e)\n                    }\n            \n            # ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼\n            successful_tests = sum(1 for test in test_results['tests'].values() if test['success'])\n            total_tests = len(test_results['tests'])\n            \n            logger.info(\"\\n\" + \"=\"*60)\n            logger.info(\"ğŸ§ª COMPREHENSIVE TEST RESULTS\")\n            logger.info(\"=\"*60)\n            logger.info(f\"Endpoint: {self.endpoint_name}\")\n            logger.info(f\"Success Rate: {successful_tests}/{total_tests} tests passed\")\n            \n            for test_name, result in test_results['tests'].items():\n                status = \"âœ… PASS\" if result['success'] else \"âŒ FAIL\"\n                logger.info(f\"  {test_name}: {status}\")\n            \n            logger.info(\"=\"*60)\n            \n            return test_results\n            \n        except Exception as e:\n            logger.error(f\"âŒ Comprehensive test failed: {str(e)}\")\n            test_results['error'] = str(e)\n            return test_results


def main():
    \"\"\"\n    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°\n    \"\"\"\n    # è¨­å®šï¼ˆå®Ÿéš›ã®å€¤ã«å¤‰æ›´ã—ã¦ãã ã•ã„ï¼‰\n    endpoint_name = \"lightgbm-binary-endpoint-v2-1722697200\"  # å®Ÿéš›ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå\n    bucket = \"sagemaker-us-east-1-123456789012\"  # å®Ÿéš›ã®ãƒã‚±ãƒƒãƒˆå\n    s3_prefix = \"lightgbm-binary-classification-v2\"  # å®Ÿéš›ã®S3ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹\n    region = \"us-east-1\"  # å®Ÿéš›ã®ãƒªãƒ¼ã‚¸ãƒ§ãƒ³\n    \n    # ãƒ†ã‚¹ã‚¿ãƒ¼åˆæœŸåŒ–\n    tester = LightGBMV2Tester(endpoint_name, region)\n    \n    # åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ\n    results = tester.run_comprehensive_test(bucket, s3_prefix)\n    \n    # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜\n    with open('test_results_v2.json', 'w') as f:\n        json.dump(results, f, indent=2, default=str)\n    \n    logger.info(\"Test results saved to test_results_v2.json\")\n    \n    return results


if __name__ == \"__main__\":\n    results = main()
